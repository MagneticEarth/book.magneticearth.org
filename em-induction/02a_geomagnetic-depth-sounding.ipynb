{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Electromagnetic Sounding using Geomagnetic Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**IAGA Summer School 2025**, Lisbon, Portugal  \n",
    "*Alexander Grayver*, University of Cologne "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implemented here the so-called **Geomagnetic Depth Sounding** method (also referred to as **Z/H**-method) to retrieve the 1-D electrical conductivity of the mantle under observatories. The method was first elaborated in [Banks 1969](https://doi.org/10.1111/j.1365-246X.1969.tb00252.x).\n",
    "\n",
    "At periods longer than 2 days, the external magnetic field variations at mid latitudes are dominated by the magnetospheric ring current (RC) source. This source produces the magnetic field at the surface that can, to first-order, represented by the first zonal harmonic $P_1^0 (\\cos \\theta)$, where $\\theta$ is the colatitude. Under this assumption about the geometry of the external geomagnetic field, a transfer function called $C$-response can be estimated at period $T$ as\n",
    "\n",
    "$$\n",
    "C(\\omega; \\sigma) = -\\frac{a}{2}\\tan(\\theta)\\frac{Z}{H},\n",
    "$$\n",
    "\n",
    "where $a = 6371.2$ km is the mean Earth's radius, $\\omega = 2\\pi/T$ is the angular frequency. $Z \\equiv -\\tilde{B}_r(\\tilde{\\theta},\\tilde{\\phi},\\omega), H \\equiv -\\tilde{B}_{\\theta}(\\tilde{\\theta},\\tilde{\\phi},\\omega)$, are vertical and horizontal (North) magnetic field components expressed in centered dipole (geomagnetic) coordinates at a location on the Earth's surface characterized by geomagnetic co-latitude $\\tilde{\\theta}$ and longitude $\\tilde{\\phi}$. The $\\sigma \\equiv \\sigma(r)$ is the electrical conductivity model of the subsurface, here assumed to vary only with the radial distance from the center.\n",
    "\n",
    "Note that we assume that the magnetic field consists of only external and corresponding induced (internal) components. That is, the effect of all other time-varying magnetic field sources, such as the core, has been subtracted from $Z$ and $H$ prior to the analysis.\n",
    "\n",
    "At this point, a few properties of the $C$-response can be mentioned (see [Weidelt 1972](https://www.mtnet.info/papers/PeterWeidelt/Weidelt_1972_ZGeophys.pdf) for more details):\n",
    "\n",
    "- The period $T$ is proportional to the depth of sounding. Longer periods (smaller frequencies) attenuate slower, thus sounding deeper and vice versa.\n",
    "- For a 1-D subsurface conductivity model, real part of $C$-response is the monotonically increasing function of period.\n",
    "- For a 1-D subsurface conductivity model, imaginary part is of the same sign (never crosses zero). Its sign depends on the Fourier convention.\n",
    "\n",
    "Apparent resistivity can be expressed from $C$-response as\n",
    "\n",
    "$$\n",
    "\\rho^{app} = \\omega\\mu|C|^2\n",
    "$$\n",
    "\n",
    "For more details about $C$-responses and various practical aspects, refer to the literature:\n",
    "\n",
    "- Banks, R. J. (1969). Geomagnetic variations and the electrical conductivity of the upper mantle. Geophysical Journal International, 17(5), 457-487.\n",
    "- Weidelt, P. (1972). The Inverse Problem of Geomagnetic Induction, Zeitschriftfiir Geophysik, 1972, Band 38, Seite 257-289. Physica-Verfag, Wiirzburg\n",
    "- Olsen, N. (1998). The electrical conductivity of the mantle beneath Europe derived from C-responses from 3 to 720 hr. Geophysical Journal International, 133(2), 298-308.\n",
    "- Schmucker, U. (1999). A spherical harmonic analysis of solar daily variations in the years 1964–1965: response estimates and source fields for global induction—II. Results. Geophysical Journal International, 136(2), 455-476.\n",
    "- Semenov, A., & Kuvshinov, A. (2012). Global 3-D imaging of mantle conductivity based on inversion of observatory C-responses—II. Data analysis and results. Geophysical Journal International, 191(3), 965-992."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Downloading the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We will rely on the [ViresClient](https://viresclient.readthedocs.io/en/latest/) server that provides an access to quality-controlled database of ground observatory data delivered by the [INTERMAGNET](https://intermagnet.org/) and the [World Data Centre (WDC) for Geomagnetism](http://www.wdc.bgs.ac.uk/). Development of ViresClient is endorsed by the European Space Agency in the Earth Observation program space mission [Swarm](https://www.esa.int/Applications/Observing_the_Earth/FutureEO/Swarm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Install dipole which will be used later\n",
    "%pip install git+https://github.com/klaundal/dipole.git@8acb53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import warnings\n",
    "\n",
    "import chaosmagpy.coordinate_utils as c_utils\n",
    "\n",
    "from viresclient import SwarmRequest\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the data from `Vires` server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, setup a connection with the Vires server (note you need to login/register the first time you access the server):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = SwarmRequest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data are available as three collections: 1 second and 1 minute cadences, as well as specially derived hourly means over the past century. There are three data types AUX_OBSH (hour), AUX_OBSM (minute) and AUX_OBSS (second). For example, to access the hourly data, we need the collection name *SW_OPER_AUX_OBSH2_*. For other types, relevant collections can be requested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(request.available_collections(\"AUX_OBSH\", details=False))\n",
    "print(request.available_collections(\"AUX_OBSM\", details=False))\n",
    "print(request.available_collections(\"AUX_OBSS\", details=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within each collection, the following variables are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(request.available_measurements(\"SW_OPER_AUX_OBSH2_\"))\n",
    "print(request.available_measurements(\"SW_OPER_AUX_OBSM2_\"))\n",
    "print(request.available_measurements(\"SW_OPER_AUX_OBSS2_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `B_NEC` is the magnetic field vector in North (X), East (Y) and Center (Z) coordinate system\n",
    "- `F` is total field intensity\n",
    "- `IAGA_code` gives the official three-letter [IAGA INTERMAGNET](https://intermagnet.org/metadata/#/imos) codes that identify each observatory\n",
    "- `Quality` is either \"D\" or \"Q\" to indicate whether data is definitive (D) or quasi-definitive (Q)\n",
    "- `ObsIndex` is an increasing integer (0, 1, 2...) attached to the hourly data - this indicates a change in the observatory (e.g. of precise location) while the 3-letter IAGA code remained the same\n",
    "\n",
    "Note that the **IAGA_code** variable is necessary in order to distinguish records from different observatories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `available_observatories` to find possible IAGA codes\n",
    "\n",
    "We can get a dataframe containing the availability times of data from all the available observatories for a given collection (in this case hourly means):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_observatories = request.available_observatories(\"SW_OPER_AUX_OBSH2_\", details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `Vires` returned a special object of type [pandas.DataFrame](https://pandas.pydata.org/docs/getting_started/intro_tutorials/01_table_oriented.html): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(all_observatories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object is essentially a very advanced table with rich functional related to indexing, searching and extracting data. Think of it as an analogue of an Excel sheet, but in python. Let us just show part of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_observatories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we have more than 200 ground observatories with their starting and end operation times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get a list of only the available observatories during a given time window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_observatories = request.available_observatories(\"SW_OPER_AUX_OBSH2_\", '2013-12-01', '2024-12-31', details=True)\n",
    "all_observatories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot observatories on a world map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cartopy matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "proj = ccrs.Robinson()     # nice world projection; try PlateCarree() if you prefer\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = plt.axes(projection=proj)\n",
    "ax.set_global()\n",
    "\n",
    "# base map\n",
    "ax.add_feature(cfeature.LAND, facecolor=\"#f2f2f2\")\n",
    "ax.add_feature(cfeature.OCEAN, facecolor=\"#d8ecff\")\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "ax.gridlines(draw_labels=False, linewidth=0.3, alpha=0.5)\n",
    "\n",
    "ax.scatter(all_observatories.Longitude, all_observatories.Latitude, marker='o', s=6, transform=ccrs.PlateCarree(), color=\"tab:red\")\n",
    "\n",
    "# Labels (nudge by a small lon/lat offset to reduce overlap)\n",
    "label_dx = 2.0   # degrees longitude to nudge text\n",
    "label_dy = 2.0   # degrees latitude to nudge text\n",
    "\n",
    "for _, row in all_observatories.iterrows():\n",
    "    label = str(row.get(\"site\", \"\"))\n",
    "    if label:\n",
    "        ax.text(row[\"Longitude\"] + label_dx,\n",
    "                row[\"Latitude\"] + label_dy,\n",
    "                label,\n",
    "                transform=ccrs.PlateCarree(),\n",
    "                fontsize=8, weight=\"bold\",\n",
    "                zorder=4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### European map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cartopy matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "proj = ccrs.Robinson()     # nice world projection; try PlateCarree() if you prefer\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = plt.axes(projection=proj)\n",
    "\n",
    "ax.set_extent([-25, 45, 34, 72], crs=ccrs.PlateCarree())\n",
    "\n",
    "# base map\n",
    "ax.add_feature(cfeature.LAND, facecolor=\"#f2f2f2\")\n",
    "ax.add_feature(cfeature.OCEAN, facecolor=\"#d8ecff\")\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "ax.gridlines(draw_labels=False, linewidth=0.3, alpha=0.5)\n",
    "\n",
    "ax.scatter(all_observatories.Longitude, all_observatories.Latitude, marker='o', s=6, transform=ccrs.PlateCarree(), color=\"tab:red\")\n",
    "\n",
    "# Labels (nudge by a small lon/lat offset to reduce overlap)\n",
    "label_dx = 2.0   # degrees longitude to nudge text\n",
    "label_dy = 2.0   # degrees latitude to nudge text\n",
    "\n",
    "# labels\n",
    "for _, row in all_observatories.iterrows():\n",
    "    txt = ax.text(row[\"Longitude\"], row[\"Latitude\"], str(row[\"site\"]),\n",
    "                  transform=ccrs.PlateCarree(),\n",
    "                  fontsize=8, weight=\"bold\", zorder=4,\n",
    "                  clip_on=True)               # <-- important\n",
    "    # clip to the map’s outline (so nothing draws outside the projected boundary)\n",
    "    try:\n",
    "        txt.set_clip_path(ax.outline_patch)\n",
    "    except Exception:\n",
    "        pass  # fallback if Cartopy version lacks outline_patch\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `IAGA_code` to specify a particular observatory\n",
    "\n",
    "Subset the collection with a special collection name like `\"SW_OPER_AUX_OBSH2_:<IAGA_code>\"` to get data from only that observatory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IAGA_code = \"FUR\"\n",
    "\n",
    "request = SwarmRequest()\n",
    "request.set_collection(\"SW_OPER_AUX_OBSH2_:\" + IAGA_code)\n",
    "request.set_products(measurements=[\"IAGA_code\", \"B_NEC\"], \n",
    "                     auxiliaries=[\"Kp\", \"Dst\"],\n",
    "                     models=[\"MCO_SHA_2C\", \"MLI_SHA_2C\"])\n",
    "data = request.get_between(\"2014-01-01\", \"2023-12-31\")\n",
    "\n",
    "# Represent data as pandas.DataFrame, drop the empty column \"Spacecraft\" (obviously, the data is measured on the ground)\n",
    "data = data.as_dataframe(expand=True)\n",
    "# Rename B_NEC (North,East,Center) columns into X,Y,Z to match our convention from the lectures\n",
    "data = data.rename(columns={f\"B_NEC_{i}\": j for i, j in zip(\"NEC\", \"XYZ\")})\n",
    "# Show the data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to the observatory data, we also fetched the corresponding core and lithospheric field values as predicted by the Comprehensive Inversion models. We will use these later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the time series of all three components as a function of time using [matplotlib](https://matplotlib.org/stable/tutorials/pyplot.html) functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, figsize=(15, 7), sharey=False, sharex=True)\n",
    "fig.suptitle('Magnetic field at observatory ' + IAGA_code)\n",
    "for i, component in enumerate(\"XYZ\"):\n",
    "    axes[i].plot(data.index, data[component],label=component)\n",
    "    axes[i].set_ylabel(f\"{component} (nT)\")\n",
    "    axes[i].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isn't it cool, few lines of python code and we have all geomagnetic data within the reach! Let's look into more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing the core and crustal field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time series are dominated by the core field and also affected by the static crustal field. Therefore, before we can assume that the time-variations originate from the external source (e.g. magnetosphere) and corresponding induced components, we need to subtract the other sources, most importantly the core. \n",
    "\n",
    "To this end, we use modeled core field as given by the Comprehensive Inversion and subtract it from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_obs = data[['X','Y','Z']].to_numpy()\n",
    "B_core = data[['B_NEC_MCO_SHA_2C_N','B_NEC_MCO_SHA_2C_E','B_NEC_MCO_SHA_2C_C']].to_numpy()\n",
    "B_crust = data[['B_NEC_MLI_SHA_2C_N','B_NEC_MLI_SHA_2C_E','B_NEC_MLI_SHA_2C_C']].to_numpy()\n",
    "\n",
    "dB = B_obs - B_core - B_crust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, figsize=(15, 7), sharey=False, sharex=True)\n",
    "fig.suptitle('Magnetic field variations at observatory ' + IAGA_code)\n",
    "for i, component in enumerate(\"XYZ\"):\n",
    "    axes[i].plot(data.index, dB[:,i],label=component)\n",
    "    axes[i].set_ylabel(f\"{component} (nT)\")\n",
    "    axes[i].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some residual (non-modelled) constant offset is still visible, let's just detrend it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import detrend\n",
    "\n",
    "# Detrend along rows (each column separately)\n",
    "dB = dB - np.nanmean(dB, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, figsize=(15, 7), sharey=False, sharex=True)\n",
    "fig.suptitle('Magnetic field variations at observatory ' + IAGA_code)\n",
    "for i, component in enumerate(\"XYZ\"):\n",
    "    axes[i].plot(data.index, dB[:,i],label=component)\n",
    "    axes[i].set_ylabel(f\"{component} (nT)\")\n",
    "    axes[i].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the ring current is organized with respect to the geomagnetic dipole, we should transform the vector field and the coordinates of the observatory to geomagnetic coordinates. To this end, we will use the [dipole](https://github.com/klaundal/dipole/tree/main) package by Karl Laundal (just type `dipole.geo2mag?` to check the documentation of the function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dipole\n",
    "\n",
    "latitude = data['Latitude'].iloc[0] # Geographic latitude\n",
    "longitude = data['Longitude'].iloc[0] # Geographic longitude\n",
    "\n",
    "# Columns are North, East, Center\n",
    "dB_mag = dB.copy()\n",
    "\n",
    "dipole_2015 = dipole.Dipole(2015.) # IGRF epoch 2015\n",
    "\n",
    "latitude_mag, longitude_mag, dB_mag[:,1], dB_mag[:,0] = dipole_2015.geo2mag(latitude, longitude, Ae = dB[:,1], An = dB[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dipole_2015.geo2mag?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of electromagnetic transfer function\n",
    "\n",
    "Note that in the equation above, the magnetic field components $Z, H$ are expressed at an angular frequency $\\omega$, but in reality we measure magnetic field in time. The relation between the vertical component time-series $z(t)$ its frequency domain is expressed by the Fourier integral (the expression for $H$ component is analogous):\n",
    "$$\n",
    "z(t)=\\frac{1}{2\\pi}\\int\\limits_{-\\infty}^{\\infty}Z(\\omega)e^{\\mathrm{i}\\omega t}\\mathrm{d}\\omega,\n",
    "$$\n",
    "\n",
    "Next, we want to estimate a transfer function at a period of $T$ hours. To this end, we first split the hourly mean time-series into $L$ equal segments (also called realizations), each of length $T$ samples. For realization $l$, we perform the discrete Fourier transformation\n",
    "\n",
    "$$\n",
    "Z_l(\\omega) = \\sum_{k=1}^{T} \\hat{Z}_{l,k} \\exp(-\\mathrm{i}\\omega k),\n",
    "$$\n",
    "\n",
    "where $\\hat{Z}_{l,k}$ is the $k$-th value in the $l$-th realization (segment), $\\omega = 2\\pi / T$. The same is done for the horizontal component $H$.\n",
    "\n",
    "Then we use the least-squares spectral stacking method to estimate the $C$-response as\n",
    "\n",
    "$$\n",
    "C = - \\frac{a}{2}\\tan(\\theta)\\frac{\\langle ZH^* \\rangle }{\\langle HH^* \\rangle},\n",
    "$$\n",
    "\n",
    "where $H^*$ is the complex conjugate of $H$ and $\\langle \\cdots \\rangle$ denotes the summation over $L$ realizations\n",
    "\n",
    "$$\n",
    "\\langle ZH^* \\rangle = \\sum_{l=1}^L Z_l H_l^*\n",
    "$$\n",
    "\n",
    "As a quality measure of the estimated $C$-response, we use the [squared coherency](https://en.wikipedia.org/wiki/Coherence_(signal_processing)) defined as\n",
    "\n",
    "$$\n",
    "coh^2 = \\frac{|\\langle ZH^* \\rangle|^2}{\\langle ZZ^* \\rangle\\langle HH^* \\rangle}\n",
    "$$\n",
    "\n",
    "Squared coherence is a number between 0 and 1. The high quality transfer function yields a value closer to a unity (provided all assumptions about the source geometry hold).\n",
    "\n",
    "The uncertainty (error) of the least-squares estimate is given by\n",
    "\n",
    "$$\n",
    "\\delta C^2 = |C|^2 (1 - coh^2) \\frac{(1/\\beta)^{1/L-1} - 1}{coh^2},\n",
    "$$\n",
    "\n",
    "where $1 - \\beta$ is the probability that modulus $|C|$ lies within the error $|C| \\pm \\delta C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the implementation of the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_spectral_stacking(Z, H, Periods):\n",
    "    \"\"\"\n",
    "    Univariate spectral stacking for Z/H sounding method\n",
    "    Alexander Grayver, 2025\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Z : 1D array-like (Nt,)\n",
    "        Output-channel time series.\n",
    "    H : 1D array-like (Nt,)\n",
    "        Input-channel time series.\n",
    "    Periods : 1D array-like (NPeriods,)\n",
    "        Periods at which TFs are estimated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TF : np.ndarray (NPeriods,)\n",
    "        Estimated complex transfer function at each period.\n",
    "    dTF : np.ndarray (NPeriods,)\n",
    "        Standard error estimates.\n",
    "    coh2 : np.ndarray (NPeriods,)\n",
    "        Squared coherences.\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = np.asarray(Z)\n",
    "    H = np.asarray(H)\n",
    "    Periods = np.asarray(Periods)\n",
    "    \n",
    "    TF_list = []\n",
    "    dTF_list = []\n",
    "    coh2_list = []\n",
    "\n",
    "    for pidx, period in enumerate(Periods):\n",
    "        \n",
    "        length = int(np.round(period))\n",
    "\n",
    "        H_f = []\n",
    "        Z_f = []\n",
    "\n",
    "        cfac = np.exp(-2j * np.pi * np.arange(length) / period)        \n",
    "        for i in range(0, len(Z) - (length - 1), length):\n",
    "\n",
    "            Z_seg = Z[i + np.arange(length)]\n",
    "            H_seg = H[i + np.arange(length)]\n",
    "\n",
    "            if not (np.isnan(Z_seg).any() or np.isnan(H_seg).any()):\n",
    "                H_f.append(np.sum(H_seg * cfac))\n",
    "                Z_f.append(np.sum(Z_seg * cfac))\n",
    "\n",
    "        L = len(H_f)\n",
    "\n",
    "        print(f\"Period no. {pidx+1} of {len(Periods)}, {L} events\")\n",
    "\n",
    "        H_f = np.array(H_f, dtype=np.complex128)\n",
    "        Z_f = np.array(Z_f, dtype=np.complex128)\n",
    "\n",
    "        TF = np.vdot(H_f, Z_f) / np.vdot(H_f, H_f)\n",
    "        TF_list.append(TF)\n",
    "\n",
    "        # Squared coherence\n",
    "        coh2 = np.abs(np.vdot(H_f, Z_f))**2 / (np.vdot(Z_f,Z_f)*np.vdot(H_f,H_f)).real\n",
    "        coh2_list.append(coh2)\n",
    "\n",
    "        # Uncertainty (Standard deviation) of the estimate\n",
    "        beta = 0.95 # 1 - beta is the confidence interval, i.e. probability that the absolute unit value lies within error limits ±δTF.\n",
    "        dTF = np.sqrt(((1. - coh2) * ((1/beta)**(1 / (L - 1)) - 1)) / coh2)\n",
    "        dTF_list.append(dTF)\n",
    "\n",
    "    TF = np.asarray(TF_list, dtype=np.complex128)\n",
    "    dTF = np.asarray(dTF_list, dtype=float)\n",
    "    coh2 = np.asarray(coh2_list, dtype=float)\n",
    "    return TF, dTF, coh2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify inputs for data processng and call the spectral stacking function implemented above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_start_h = 48;     # Shortest_period of the transfer function (>= Nyquist);\n",
    "T_max_h   = 50*24;  # Longest of the desired transfer function;\n",
    "\n",
    "Periods = np.logspace(np.log10(T_start_h),np.log10(T_max_h), 16);\n",
    "\n",
    "# Note we used magnetic field in the transformed geomagnetic coordinates\n",
    "[TF, dTF, coh2] = univariate_spectral_stacking(dB_mag[:,2], dB_mag[:,0], Periods);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated transfer functions returned by the function **univariate_spectral_stacking** are just spectral ratios between vertical and horitonal components. We need to convert to the $C$-response following the equation above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 6371200 # Earth's mean radius\n",
    "theta_mag = 90 - latitude_mag[0] # Geomagnetic co-latitude\n",
    "\n",
    "C = - a / 2 * np.tan(np.deg2rad(theta_mag)) * TF\n",
    "dC = np.abs(C) * dTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the $C$-response and its uncertainty have units of **m**. For convenience, we plot them in **km**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_coh, ax_tf) = plt.subplots(2, 1, sharex=True, figsize=(8, 6),\n",
    "                                    gridspec_kw={'height_ratios': [1, 2]})\n",
    "\n",
    "# Coherence plot\n",
    "ax_coh.plot(Periods/24, coh2, 'o-', color='tab:blue')\n",
    "ax_coh.set_ylabel('Squared Coherence')\n",
    "ax_coh.set_ylim(0, 1.05)\n",
    "ax_coh.set_xscale('log')\n",
    "ax_coh.grid(True)\n",
    "\n",
    "# TF plot: real and imaginary parts\n",
    "ax_tf.errorbar(Periods/24, C.real/1e3, yerr=dC/1e3, fmt='.', label='Real(C)', color='tab:orange')\n",
    "ax_tf.errorbar(Periods/24, C.imag/1e3, yerr=dC/1e3, fmt='.', label='Imag(C)', color='tab:green')\n",
    "ax_tf.set_xlabel('Period [day]')\n",
    "ax_tf.set_ylabel('C [km]')\n",
    "ax_tf.set_xscale('log')\n",
    "ax_tf.grid(True)\n",
    "ax_tf.legend()\n",
    "\n",
    "fig.suptitle('C-response for observatory ' + IAGA_code)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of the 1-D conductivity profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find a simple 1-D conductivity model that would explain the data. The 1-D model is given by layer thicknesses and conductivity values. In this exercise, we will seek only layer conductivities and and our model will consist of three layers. Since electrical conductities can vary over many orders of magnitude, we will invert for the log-conductivity. The model vector is then\n",
    "\n",
    "$$\n",
    "\\mathbf{m} = [\\log_{10}(m_1), \\log_{10}(m_2), \\log_{10}(m_3)]\n",
    "$$\n",
    "\n",
    "To find the conductivity values that minimize the misfit, we solve the following minimization problem:\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{m}} \\Phi_d(\\mathbf{m}) + \\alpha\\Phi_m(\\mathbf{m})\n",
    "$$\n",
    "\n",
    "Where $\\Phi_d$ is the data misfit term given by\n",
    "\n",
    "$$\n",
    "\\Phi_d(\\mathbf{m}) = \\left(C^{obs} - C^{mod}(\\mathbf{m})\\right)^H \\Sigma_d^{-1} \\left(C^{obs} - C^{mod}(\\mathbf{m})\\right),\n",
    "$$\n",
    "\n",
    "where $C^{obs}$ is the vector of estimated transfer functions, $C^{mod}(\\mathbf{m})$ is the vector of predicted transfer functions. The subscript $H$ is complex-conjugate transpose. The data covariance matrix $\\Sigma_d$ is a diagonal matrix with the estimated $C$-response uncertainties \n",
    "\n",
    "$$\n",
    "\\Sigma_d = \\mathrm{diag}[\\delta C_1, \\dots, \\delta C_{N_d}]\n",
    "$$\n",
    "\n",
    "The $\\alpha$ is the regularization parameter and  $\\Phi_m$ is the regularization term expressed as\n",
    "\n",
    "$$\n",
    "\\Phi_m(\\mathbf{m}) = \\mathbf{m}^T\\mathbf{m}\n",
    "$$\n",
    "\n",
    "Which minimizes the model norm, thereby preferring simpler models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can implement the objective function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(radii, sigma, periods, C_obs, dC_obs, regpar):\n",
    "    C_mod, _, _, _ = c_utils.q_response_1D(periods, sigma, radii / 1e3, n = 1, kind = 'constant')\n",
    "    C_mod *= 1e3 # km to m\n",
    "    \n",
    "    # Misfit\n",
    "    residuals = (C_obs - C_mod) / dC_obs\n",
    "    phi_d = np.vdot(residuals,residuals).real\n",
    "\n",
    "    phi_m = np.linalg.norm(np.log10(sigma))**2\n",
    "    \n",
    "    return phi_d + regpar*phi_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the three layer model with layer boundaries at the top and bottom of the Mantle Transition Zone (i.e. 410 and 660 km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz = [410e3, 250e3, 2200e3] # thickness of the layers in m\n",
    "radii = a - np.cumsum([0,] + dz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have three parameters, we will seek the minimum by using the bruteforce (grid-search) method. That is, we will test log-spaced conductivity values within a range for each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_values = np.logspace(-4, 1, 21)  # was 26\n",
    "print(sigma_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid bulky nested loops, we use the co-scalled defined using the product method. This method will create all combinations of values and we will be able to iterate over them within a single loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "combinations = product(sigma_values, repeat=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over model combinations and compute the objective function, then store the result in an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "results = [(sigma, phi(radii, sigma, Periods*3600, C, dC, regpar=1000)) for sigma in combinations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once finished, we can see the model with the minimum misfit, corresponding to the model that best fits our observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sigma, best_misfit = min(results, key=lambda t: t[1])\n",
    "\n",
    "print(\"Lowest misfit model: \", best_sigma)\n",
    "print(\"Lowest misfit value: \", best_misfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict the responses for the best-fit model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_best, _, _, _ = c_utils.q_response_1D(Periods*3600, best_sigma, radii / 1e3, n = 1, kind = 'constant')\n",
    "C_best *= 1e3 # km to m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the observaed and modelled (best-fit model) responses together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_coh, ax_tf) = plt.subplots(2, 1, sharex=True, figsize=(8, 6),\n",
    "                                    gridspec_kw={'height_ratios': [1, 2]})\n",
    "\n",
    "# Coherence plot\n",
    "ax_coh.plot(Periods/24, coh2, 'o-', color='tab:blue')\n",
    "ax_coh.set_ylabel('Squared Coherence')\n",
    "ax_coh.set_ylim(0, 1.05)\n",
    "ax_coh.set_xscale('log')\n",
    "ax_coh.grid(True)\n",
    "\n",
    "# TF plot: real and imaginary parts\n",
    "ax_tf.errorbar(Periods/24, C.real/1e3, yerr=dC/1e3, fmt='.', label='Real(C)', color='tab:orange')\n",
    "ax_tf.errorbar(Periods/24, C.imag/1e3, yerr=dC/1e3, fmt='.', label='Imag(C)', color='tab:green')\n",
    "ax_tf.plot(Periods/24, C_best.real/1e3, label='Best fit model', color='k')\n",
    "ax_tf.plot(Periods/24, C_best.imag/1e3, label=None, color='k')\n",
    "ax_tf.set_xlabel('Period [day]')\n",
    "ax_tf.set_ylabel('C [km]')\n",
    "ax_tf.set_xscale('log')\n",
    "ax_tf.grid(True)\n",
    "ax_tf.set_xlim(1, 60)\n",
    "ax_tf.legend()\n",
    "\n",
    "fig.suptitle('C-response for observatory ' + IAGA_code)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the models with the global electrical conductivity model from [Grayver et al. 2017](https://github.com/agrayver/ConductivityProfile):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['xtick.labelsize'] = 14\n",
    "mpl.rcParams['ytick.labelsize'] = 14\n",
    "\n",
    "model_2017 = np.loadtxt('joint_model_Grayver2017.dat')\n",
    "\n",
    "fig=plt.figure(figsize=(5, 6), facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.step(model_2017[:,1], model_2017[:,0]/1e3, where='pre', label = 'Global Model')\n",
    "\n",
    "plt.step(np.r_[best_sigma, best_sigma[-1]], (a-radii)/1e3, where='pre', label = IAGA_code)\n",
    "\n",
    "plt.plot([1e-4, 1e6], [410, 410], color='gray', linestyle='--', linewidth='1')\n",
    "plt.plot([1e-4, 1e6], [660, 660], color='gray', linestyle='--', linewidth='1')\n",
    "\n",
    "plt.xlim(1e-4, 1e2);\n",
    "plt.ylim(0, 2300);\n",
    "plt.xlabel(r'Conductivity $\\sigma$ [S/m]', fontsize=14)\n",
    "plt.ylabel(r'Depth [km]', fontsize=14)\n",
    "plt.xscale('log')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.legend()    \n",
    "#plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('models.png', dpi=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vary the regularization parameter `regpar` and check how this changes the model and the data misfit. \n",
    "- Try estimating transfer function for longer and/or shorter periods. Which problems do you encounter (pay attention to the squared coherency and monotonic property of the $C$-response)?\n",
    "- Try different mid-latitude observatories, for instance Boulder, US (BOU), or Alice Springs (ASP).\n",
    "- Also try some high-latitude observatories: does the method still work? Are all underlying assumptions still hold? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data processing methods used in research are a lot more advanced, and include robust statistics to mitigate outliers and non-gaussian noise, window tapering to lower the spectral leakage, and bias corrections. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
